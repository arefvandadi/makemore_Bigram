We will create a Bigram model with self-attetion block
The self-Attention block is similar to what was used in Attention is All You Need paper
The LLM model will use tinyshakespeare text file (book) to train itself and create more words similar to the book.
