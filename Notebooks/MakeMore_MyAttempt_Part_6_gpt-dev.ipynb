{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOLcdKXjl+TU0IyZDLMZqUh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynDsEvonfTd9","executionInfo":{"status":"ok","timestamp":1709472391565,"user_tz":300,"elapsed":423,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"9b0bf8df-8d52-48a2-98a2-d0c13da0bca7"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-03 13:26:31--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt’\n","\n","\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n","\n","2024-03-03 13:26:31 (19.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n","\n"]}],"source":["# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n","!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","source":["with open(\"input.txt\", 'r', encoding='utf-8') as F:\n","  book = F.read()"],"metadata":{"id":"yxpXyAwnnoLx","executionInfo":{"status":"ok","timestamp":1709472392994,"user_tz":300,"elapsed":136,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(book[:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YF6HYc-2ockq","executionInfo":{"status":"ok","timestamp":1709472393875,"user_tz":300,"elapsed":144,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"fbe6e276-4f46-4254-8225-82d8ba8f8009"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n"]}]},{"cell_type":"code","source":["book[:100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"NCup9d5Son3y","executionInfo":{"status":"ok","timestamp":1709472394646,"user_tz":300,"elapsed":4,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"ff524288-20e3-4966-d23a-a96e88e9913c"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["len(book)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ladeUYf0pCUh","executionInfo":{"status":"ok","timestamp":1709472395443,"user_tz":300,"elapsed":175,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"e2687019-f46f-401a-f1f1-e847a4f1f296"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1115394"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["r = sorted(set(book))\n","chars =''.join(r)\n","print(chars)\n","charsize = len(chars)\n","print(charsize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxkEb6pqpkvX","executionInfo":{"status":"ok","timestamp":1709472395757,"user_tz":300,"elapsed":186,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"bf57f8e6-b47e-4d19-a9c6-402735c74626"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}]},{"cell_type":"code","source":["## I used rfind() function to create my encoder and deccoder instead of using dictionary which was used in the Original code\n","encoder = lambda c: [chars.rfind(c[i]) for i in range(len(c))]\n","decoder = lambda c: \"\".join([chars[i] for i in c])"],"metadata":{"id":"Zz_cjpltqLLg","executionInfo":{"status":"ok","timestamp":1709472396013,"user_tz":300,"elapsed":2,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(encoder('Hello There'))\n","print(decoder(encoder('Hello There')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9RwnY_HzS_U","executionInfo":{"status":"ok","timestamp":1709472396460,"user_tz":300,"elapsed":165,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"15fb3bcd-84b7-4300-c64a-fac3880b12fe"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[20, 43, 50, 50, 53, 1, 32, 46, 43, 56, 43]\n","Hello There\n"]}]},{"cell_type":"code","source":["book_digits_List=encoder(book)"],"metadata":{"id":"T-j2pGHH1Edn","executionInfo":{"status":"ok","timestamp":1709472397471,"user_tz":300,"elapsed":241,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print('First 15 characters in the book:  ',book[:15])\n","print('First 15 codes in the encoded book:  ',book_digits_List[:15])\n","print('\\nLength of the characters in Book:     ',len(book))\n","print('Length of the codes in Encoded Book:  ',len(book_digits_List))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68YnU8L23BRI","executionInfo":{"status":"ok","timestamp":1709472398170,"user_tz":300,"elapsed":129,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"8aacf39e-607f-47e1-eef2-2f4a433399e8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["First 15 characters in the book:   First Citizen:\n","\n","First 15 codes in the encoded book:   [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0]\n","\n","Length of the characters in Book:      1115394\n","Length of the codes in Encoded Book:   1115394\n"]}]},{"cell_type":"code","source":["# Convert Encoded Book from python List to PyTorch Tensor\n","import torch\n","book_digits = torch.tensor(book_digits_List)\n","book_digits[:15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkWt8aS8BhK2","executionInfo":{"status":"ok","timestamp":1709472404795,"user_tz":300,"elapsed":5769,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"22bcb85e-8b71-4814-85be-98f22bc2ffdc"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["n=len(book_digits)*9//10\n","Train_data = book_digits[:n]\n","Val_data = book_digits[n:]"],"metadata":{"id":"QfMGIYwmBkX1","executionInfo":{"status":"ok","timestamp":1709472407813,"user_tz":300,"elapsed":131,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["batch_size = 4\n","context = 3\n","\n","def get_batch(x):\n","  Batch_start = torch.randint(0, len(x)-context,(batch_size,))\n","  xb = torch.stack([x[Batch_start[i]:Batch_start[i]+context] for i in range(batch_size)])\n","  yb = torch.stack([x[Batch_start[i]+1:Batch_start[i]+context+1] for i in range(batch_size)])\n","  return xb, yb\n","\n","xb, yb = get_batch(book_digits)\n","print(xb)\n","print(yb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-h9ojAwvu5Xo","executionInfo":{"status":"ok","timestamp":1709472408345,"user_tz":300,"elapsed":149,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"5f03c7fe-7c2b-4329-ac26-57c6d1e513bf"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0,  0, 17],\n","        [63,  1, 51],\n","        [56,  1, 56],\n","        [61, 53, 56]])\n","tensor([[ 0, 17, 16],\n","        [ 1, 51, 53],\n","        [ 1, 56, 43],\n","        [53, 56, 58]])\n"]}]},{"cell_type":"code","source":["# Let's define a Bigram Language model\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# nn.module inheritance is not added\n","# super().__init() is not included yet\n","\n","class NgramLanguageModel:\n","\n","  def __init__(self):\n","    self.channels = nn.Embedding(charsize,charsize)\n","    self.parameters = [self.channels.weight]\n","\n","  def forward(self,random_training_batch):\n","    # looks up in the Embedding table created in the constructor to assign weights to each character coming in\n","    logits = self.channels(random_training_batch) # Batch (B) X context (T) X Embedding/Channels (C)\n","    return logits\n","\n","  def LossFunction(self,logits,random_training_batch_nextChar):\n","    logits = logits.view(-1,charsize) # we are doing this since Pytorch functinal.cross_entropy function needs Channels to be assigned to the second dimension\n","    Target = random_training_batch_nextChar.view(-1)\n","    Loss = F.cross_entropy(logits,Target)\n","    return Loss\n","\n","  def generate(self, initiator_token, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # get the predictions\n","            logits = self.forward(initiator_token)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            initiator_token_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            initiator_token = torch.cat((initiator_token, initiator_token_next), dim=1) # (B, T+1)\n","        return initiator_token"],"metadata":{"id":"sBD6DCzE7KFV","executionInfo":{"status":"ok","timestamp":1709472412134,"user_tz":300,"elapsed":150,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# NgramLM = NgramLanguageModel()\n","# print(NgramLM.channels.weight.grad)\n","#iter([NgramLM.channels.weight])"],"metadata":{"id":"Ughr_cndaJVw","executionInfo":{"status":"ok","timestamp":1709472416609,"user_tz":300,"elapsed":117,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Create a Ngram Language Model Object\n","NgramLM = NgramLanguageModel()\n","\n","# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(NgramLM.parameters, lr=1e-3)"],"metadata":{"id":"uO9BhCgtiUwo","executionInfo":{"status":"ok","timestamp":1709472418926,"user_tz":300,"elapsed":1857,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["### TRAINING LOOP ###\n","\n","# define number of iterations to train the data\n","Iterations = 5000\n","# number of batches for each iteration\n","batch_size = 16\n","# How many characters are used to predict the next? Context = 1 --> Bigram model, Context > 1 --> Ngram model\n","context = 32\n","\n","for i in range(Iterations):\n","\n","  # get a random batch of data\n","  xb, yb = get_batch(Train_data)\n","\n","  # forward pass\n","  logits = NgramLM.forward(xb)\n","\n","  # Calculate loss\n","  Loss = NgramLM.LossFunction(logits,yb)\n","\n","  #print(NgramLM.channels.weight.grad)\n","  #Zero all parameter gradients\n","  NgramLM.channels.weight.grad = None\n","  #\n","  #print(NgramLM.channels.weight.grad)\n","\n","  # Backward Path to Calculate new grads\n","  Loss.backward()\n","\n","  # Update the weights in embedding\n","  optimizer.step()\n","\n","\n","print(Loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WCE490kzOQg","executionInfo":{"status":"ok","timestamp":1709472448079,"user_tz":300,"elapsed":8294,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"2e13b575-7f02-4cd6-c598-88bd2c29fb94"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["2.4891881942749023\n"]}]},{"cell_type":"code","source":["## Generate some text with trained model\n","print(decoder(NgramLM.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icDPhGntvf9d","executionInfo":{"status":"ok","timestamp":1709472470378,"user_tz":300,"elapsed":119,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"b38246b2-5ca8-42ac-ad6f-470c3f333cf0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","ThWhabe at !\n","TE:\n","\n","Gntl, fry plly $3pttethansYouged is an unolandrimas waYOheswatzGRUSenm Ifuerofe stowinthe\n","Andgadshera tefeato; merso berVI wone, k'n\n","Iffand minje hie sththecest azPO:\n","LI Condo ies r$kOUke.-thotrerond al tr owowiloul s.z--Fin, INshecthedomon byooirplllld:\n","RO, chen faroubrveI ash ougenele? sl\n","du serethYoyorinoORThreyo jeveit u, hes fiin my!\n","anereay th $Unear wondsthaurod fontay mesue wallitR:\n","ONur fetheak ldo,\n","OLEd!QGhif. i&x m? in'steas latV:\n","\n","Or X;\n","Duor t d!\n","\n","\n","M:\n","Yome jotMEBI:\n"]}]},{"cell_type":"markdown","source":["###__Using *Mean Value* of previous tokens to create communication between time dimension__"],"metadata":{"id":"JbIYySoKfS_G"}},{"cell_type":"code","source":["### Let's define a Bigram Language model\n","### with Mean of previous tokens\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# nn.module inheritance is not added\n","# super().__init() is not included yet\n","\n","class MeanNgramLanguageModel:\n","\n","  def __init__(self):\n","    self.channels = nn.Embedding(charsize,charsize)\n","    self.parameters = [self.channels.weight]\n","\n","  def forward(self,random_training_batch):\n","    # looks up in the Embedding table created in the constructor to assign weights to each character coming in\n","    logits = self.channels(random_training_batch) # Batch (B) X context (T) X Embedding/Channels (C)\n","    ## Masked Meaning feature of the previous tokens\n","    B,T,C = logits.shape\n","    tril = torch.tril(torch.ones(T, T))\n","    wei = torch.zeros((T,T))\n","    wei = wei.masked_fill(tril == 0, float('-inf'))\n","    wei = F.softmax(wei, dim=-1) # Context (T) X (T)\n","    logits = wei @ logits\n","    return logits\n","\n","  def LossFunction(self,logits,random_training_batch_nextChar):\n","    logits = logits.view(-1,charsize) # we are doing this since Pytorch functinal.cross_entropy function needs Channels to be assigned to the second dimension\n","    Target = random_training_batch_nextChar.view(-1)\n","    Loss = F.cross_entropy(logits,Target)\n","    return Loss\n","\n","  def generate(self, initiator_token, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # get the predictions\n","            logits = self.forward(initiator_token)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            initiator_token_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            initiator_token = torch.cat((initiator_token, initiator_token_next), dim=1) # (B, T+1)\n","        return initiator_token"],"metadata":{"id":"hIZ3OX5CfRah","executionInfo":{"status":"ok","timestamp":1709479652588,"user_tz":300,"elapsed":136,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Create a Mean Ngram Language Model Object\n","MeanNgramLM = MeanNgramLanguageModel()\n","\n","# create a PyTorch optimizer\n","optimizerMean = torch.optim.AdamW(MeanNgramLM.parameters, lr=1e-3)"],"metadata":{"id":"6KXdmyQ-4t2A","executionInfo":{"status":"ok","timestamp":1709479654127,"user_tz":300,"elapsed":154,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["### TRAINING LOOP ###\n","\n","# define number of iterations to train the data\n","Iterations = 5000\n","# number of batches for each iteration\n","batch_size = 16\n","# How many characters are used to predict the next? Context = 1 --> Bigram model, Context > 1 --> Ngram model\n","context = 32\n","\n","\n","for i in range(Iterations):\n","\n","  # get a random batch of data\n","  xb, yb = get_batch(Train_data)\n","\n","  # forward pass\n","  logits = MeanNgramLM.forward(xb)\n","\n","  # Calculate loss\n","  Loss = MeanNgramLM.LossFunction(logits,yb)\n","\n","  #print(NgramLM.channels.weight.grad)\n","  #Zero all parameter gradients\n","  MeanNgramLM.channels.weight.grad = None\n","  #\n","  #print(NgramLM.channels.weight.grad)\n","\n","  # Backward Path to Calculate new grads\n","  Loss.backward()\n","\n","  # Update the weights in embedding\n","  optimizerMean.step()\n","\n","\n","print(Loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4HTmOl345-n","executionInfo":{"status":"ok","timestamp":1709479665335,"user_tz":300,"elapsed":9931,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"fdea8349-d9ec-425a-b3e1-87f6390f5cb5"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["3.210155725479126\n"]}]},{"cell_type":"code","source":["## Generate some text with trained model\n","print(decoder(MeanNgramLM.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNoKQDgR1wQG","executionInfo":{"status":"ok","timestamp":1709479675947,"user_tz":300,"elapsed":792,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"4033eac3-93cb-4671-cd41-e96e43c97d2e"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","s iLtt  dil Iew;t.irueue noya\n","Rnbc\n"," o oIb nh\n","crAya yrecgy,uolgci&'rIy\n","otsm,\n","o  ei e,eCd   rd er d.htiysRise\n"," retIe nFeU \n"," ot eore  l,sn ecdneeh'seaedtii lcsi bshMrrF\n",",t ,lKtl\n","i,thvs.ltswCwiCt\n","t Tw iltret\n","iy'niyn u den hh tiiyoN e\n","htw.nydaoE\n","ooFttaaosenOsfento oare heeTaeleo\n","sree u  efUPhaP egtaee fo\n"," il\n","ioR.ogstH d dmhbCun dgti;ao Iils'm e omd diEZ' e h e\n","hf r\n","BsUaw  e vSdnotadgy ott fniwe\n","nAlow   ,ei\n",",Bltehi t\n","i:aQdubden mmoel w ohur\n"," fnBl'wtailhTrr ,s t bs tsRota,J?bNeleWre'df,bn o htno\n","ai\n","w h\n"]}]},{"cell_type":"markdown","source":["## __Self Attention__"],"metadata":{"id":"Wl3xAKBcPj8p"}},{"cell_type":"code","source":["torch.tril(torch.ones(3,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUzg9kwW6o8r","executionInfo":{"status":"ok","timestamp":1709418010415,"user_tz":300,"elapsed":130,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"2c99e67a-3ae8-4514-cb6e-372a2aafcebf"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 1., 1.]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["w = torch.tril(torch.ones(3,3))\n","d = w/torch.sum(w,1,keepdim=True)"],"metadata":{"id":"Qqx1eRNIP_pq","executionInfo":{"status":"ok","timestamp":1709422397785,"user_tz":300,"elapsed":93,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["torch.transpose(w,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"Bdk8CMgQQu4y","executionInfo":{"status":"error","timestamp":1709422580044,"user_tz":300,"elapsed":110,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"456fe497-7eaa-40c8-d500-3ccb78572bca"},"execution_count":32,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"transpose() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-18e2b98162f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n"]}]},{"cell_type":"code","source":["FF = torch.tensor([[1,2,4],[2,4,6]],dtype=torch.float)"],"metadata":{"id":"JVeddl4ag-T8","executionInfo":{"status":"ok","timestamp":1709423010840,"user_tz":300,"elapsed":83,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["F.softmax(FF,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRYOej_QisGO","executionInfo":{"status":"ok","timestamp":1709423239597,"user_tz":300,"elapsed":81,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"7cba6a62-0f69-44d7-ec14-100abe911379"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2689, 0.1192, 0.1192],\n","        [0.7311, 0.8808, 0.8808]])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["import math\n","math.exp(1)/(math.exp(1)+math.exp(2)+math.exp(4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLtX4w4AiyDJ","executionInfo":{"status":"ok","timestamp":1709423189588,"user_tz":300,"elapsed":87,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"ace85a00-8cb7-49a5-9882-4683035f58f3"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.04201006613406605"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["math.exp(1)/(math.exp(1)+math.exp(2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qARhE28Sjizz","executionInfo":{"status":"ok","timestamp":1709423255417,"user_tz":300,"elapsed":101,"user":{"displayName":"Aref Vandadi","userId":"09114108971880870091"}},"outputId":"6a486913-4841-4010-9940-81b9c1457f26"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2689414213699951"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":[],"metadata":{"id":"cse6tBqCkN6r"},"execution_count":null,"outputs":[]}]}